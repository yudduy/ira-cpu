"""
Tests for vc_loader.py - VC Deal Data Loader

Tests loading, filtering, and preprocessing of ClimateTech/CleanTech VC deal data.
Uses mock CSV data to avoid dependency on real PitchBook exports.
"""

import io
from unittest.mock import patch
import tempfile
import os

import pandas as pd
import pytest

from cpu_index.analysis import vc_loader


# =============================================================================
# FIXTURES
# =============================================================================

@pytest.fixture
def mock_csv_data():
    """Mock CSV data matching PitchBook export format with 6 header rows."""
    # 6 header rows to skip, then actual data
    csv_content = """Report generated by PitchBook
ClimateTech Deals Export
Date: 2024-01-15
Filtered by: All ClimateTech
Note: This is mock data
Empty row
Deal ID,Companies,Company ID,Deal Date,Announced Date,Deal Size,Deal Size Status,Deal Type,Deal Type 2,Deal Type 3,VC Round,Series,Primary Industry Sector,Primary Industry Group,Verticals,Keywords,Deal Status,Current Financing Status,HQ Location,Company State/Province,Company Country/Territory/Region,Year Founded
DEAL001,GreenTech Inc,COMP001,2024-01-15,2024-01-10,"10,000",Known,Seed Round,,,1,Seed,Energy,Clean Energy,CleanTech,solar energy,Completed,VC-backed,San Francisco,California,United States,2022
DEAL002,SolarPower Co,COMP002,2024-02-20,2024-02-15,"25,000",Known,Early Stage VC,,,2,Series A,Energy,Renewable Energy,CleanTech,renewable,Completed,VC-backed,Austin,Texas,United States,2021
DEAL003,WindEnergy Ltd,COMP003,2024-03-10,2024-03-05,"50,000",Known,Later Stage VC,,,3,Series B,Energy,Wind Power,CleanTech,wind,Completed,VC-backed,Denver,Colorado,United States,2020
DEAL004,OldTech Corp,COMP004,2007-06-15,2007-06-10,"5,000",Known,Seed Round,,,1,Seed,Energy,Solar,CleanTech,solar,Completed,VC-backed,Boston,Massachusetts,United States,2006
DEAL005,PendingDeal Inc,COMP005,2024-04-01,2024-03-25,"15,000",Known,Early Stage VC,,,2,Series A,Energy,Battery,CleanTech,battery,Pending,VC-backed,Seattle,Washington,United States,2023
DEAL006,AngelFunded Co,COMP006,2024-05-10,2024-05-05,"2,500",Known,Angel (individual),,,1,,Energy,Solar,CleanTech,angel solar,Completed,VC-backed,Miami,Florida,United States,2023
DEAL007,GrantProject Inc,COMP007,2024-06-15,2024-06-10,"30,000",Known,Grant,,,,,Energy,Research,CleanTech,grant research,Completed,Grant-funded,Chicago,Illinois,United States,2022
DEAL008,NoSizeDeal Co,COMP008,2024-07-20,2024-07-15,,Unknown,Seed Round,,,1,Seed,Energy,EV,CleanTech,electric vehicle,Completed,VC-backed,Portland,Oregon,United States,2024
"""
    return csv_content


@pytest.fixture
def mock_csv_minimal():
    """Minimal mock CSV data for basic tests."""
    csv_content = """Header 1
Header 2
Header 3
Header 4
Header 5
Header 6
Deal ID,Companies,Company ID,Deal Date,Deal Size,Deal Type,Deal Status,Primary Industry Sector
DEAL001,TestCo,COMP001,2024-01-15,"10,000",Seed Round,Completed,Energy
"""
    return csv_content


@pytest.fixture
def mock_csv_mixed_dates():
    """Mock CSV with deals spanning different years."""
    csv_content = """Header 1
Header 2
Header 3
Header 4
Header 5
Header 6
Deal ID,Companies,Company ID,Deal Date,Deal Size,Deal Type,Deal Status,Primary Industry Sector
DEAL001,OldCo,COMP001,2005-01-15,"1,000",Seed Round,Completed,Energy
DEAL002,OlderCo,COMP002,2007-12-31,"2,000",Early Stage VC,Completed,Energy
DEAL003,BoundaryCo,COMP003,2008-01-01,"3,000",Seed Round,Completed,Energy
DEAL004,NewCo,COMP004,2010-06-15,"4,000",Later Stage VC,Completed,Energy
DEAL005,RecentCo,COMP005,2024-01-15,"5,000",Early Stage VC,Completed,Energy
"""
    return csv_content


@pytest.fixture
def mock_csv_deal_sizes():
    """Mock CSV with various deal size formats."""
    csv_content = """Header 1
Header 2
Header 3
Header 4
Header 5
Header 6
Deal ID,Companies,Company ID,Deal Date,Deal Size,Deal Type,Deal Status,Primary Industry Sector
DEAL001,SmallDeal,COMP001,2024-01-15,"1,500",Seed Round,Completed,Energy
DEAL002,MediumDeal,COMP002,2024-02-15,"25,000",Seed Round,Completed,Energy
DEAL003,LargeDeal,COMP003,2024-03-15,"1,000,000",Seed Round,Completed,Energy
DEAL004,NoDeal,COMP004,2024-04-15,,Seed Round,Completed,Energy
DEAL005,ZeroDeal,COMP005,2024-05-15,0,Seed Round,Completed,Energy
DEAL006,TextDeal,COMP006,2024-06-15,N/A,Seed Round,Completed,Energy
"""
    return csv_content


def write_temp_csv(csv_content):
    """Helper to write CSV content to a temporary file and return the path."""
    fd, path = tempfile.mkstemp(suffix=".csv")
    try:
        os.write(fd, csv_content.encode("utf-8"))
    finally:
        os.close(fd)
    return path


@pytest.fixture
def temp_csv_file(mock_csv_data):
    """Create a temporary CSV file from mock data."""
    path = write_temp_csv(mock_csv_data)
    yield path
    os.unlink(path)


@pytest.fixture
def temp_csv_minimal(mock_csv_minimal):
    """Create a temporary CSV file from minimal mock data."""
    path = write_temp_csv(mock_csv_minimal)
    yield path
    os.unlink(path)


@pytest.fixture
def temp_csv_mixed_dates(mock_csv_mixed_dates):
    """Create a temporary CSV file with mixed dates."""
    path = write_temp_csv(mock_csv_mixed_dates)
    yield path
    os.unlink(path)


@pytest.fixture
def temp_csv_deal_sizes(mock_csv_deal_sizes):
    """Create a temporary CSV file with various deal sizes."""
    path = write_temp_csv(mock_csv_deal_sizes)
    yield path
    os.unlink(path)


@pytest.fixture
def loaded_vc_df(temp_csv_file):
    """Pre-loaded DataFrame for testing get_deal_summary."""
    return vc_loader.load_vc_deals(temp_csv_file)


# =============================================================================
# TEST: load_vc_deals() BASIC FUNCTIONALITY
# =============================================================================

class TestLoadVcDealsBasic:
    """Tests for basic load_vc_deals() functionality."""

    def test_load_vc_deals_returns_dataframe(self, temp_csv_minimal):
        """load_vc_deals should return a pandas DataFrame."""
        result = vc_loader.load_vc_deals(temp_csv_minimal)
        assert isinstance(result, pd.DataFrame)

    def test_load_vc_deals_adds_derived_columns(self, temp_csv_minimal):
        """load_vc_deals should add Year, Month, YearMonth, and Stage columns."""
        result = vc_loader.load_vc_deals(temp_csv_minimal)

        assert "Year" in result.columns
        assert "Month" in result.columns
        assert "YearMonth" in result.columns
        assert "Stage" in result.columns

    def test_load_vc_deals_parses_dates(self, temp_csv_minimal):
        """load_vc_deals should parse Deal Date as datetime."""
        result = vc_loader.load_vc_deals(temp_csv_minimal)
        assert pd.api.types.is_datetime64_any_dtype(result["Deal Date"])

    def test_load_vc_deals_resets_index(self, temp_csv_file):
        """load_vc_deals should reset index after filtering."""
        result = vc_loader.load_vc_deals(temp_csv_file)

        # Index should start at 0 and be continuous
        assert result.index[0] == 0
        assert list(result.index) == list(range(len(result)))

    def test_load_vc_deals_extracts_year_correctly(self, temp_csv_minimal):
        """load_vc_deals should extract year correctly from Deal Date."""
        result = vc_loader.load_vc_deals(temp_csv_minimal)
        assert result["Year"].iloc[0] == 2024

    def test_load_vc_deals_extracts_month_correctly(self, temp_csv_minimal):
        """load_vc_deals should extract month correctly from Deal Date."""
        result = vc_loader.load_vc_deals(temp_csv_minimal)
        assert result["Month"].iloc[0] == 1


# =============================================================================
# TEST: FILTERING BY DEAL TYPE
# =============================================================================

class TestFilterByDealType:
    """Tests for deal type filtering."""

    def test_filters_to_vc_deal_types_by_default(self, temp_csv_file):
        """load_vc_deals should filter to VC_DEAL_TYPES by default."""
        result = vc_loader.load_vc_deals(temp_csv_file)

        # Should include Seed Round, Early Stage VC, Later Stage VC, Angel (individual)
        # Should exclude Grant (DEAL007)
        deal_types = result["Deal Type"].unique()
        assert "Grant" not in deal_types
        for dtype in deal_types:
            assert dtype in vc_loader.VC_DEAL_TYPES

    def test_includes_seed_round(self, temp_csv_file):
        """load_vc_deals should include Seed Round deals."""
        result = vc_loader.load_vc_deals(temp_csv_file)
        assert "Seed Round" in result["Deal Type"].values

    def test_includes_early_stage_vc(self, temp_csv_file):
        """load_vc_deals should include Early Stage VC deals."""
        result = vc_loader.load_vc_deals(temp_csv_file)
        assert "Early Stage VC" in result["Deal Type"].values

    def test_includes_later_stage_vc(self, temp_csv_file):
        """load_vc_deals should include Later Stage VC deals."""
        result = vc_loader.load_vc_deals(temp_csv_file)
        assert "Later Stage VC" in result["Deal Type"].values

    def test_includes_angel_individual(self, temp_csv_file):
        """load_vc_deals should include Angel (individual) deals."""
        result = vc_loader.load_vc_deals(temp_csv_file)
        assert "Angel (individual)" in result["Deal Type"].values

    def test_custom_deal_types_filter(self, temp_csv_file):
        """load_vc_deals should accept custom deal_types parameter."""
        result = vc_loader.load_vc_deals(
            temp_csv_file, deal_types=["Seed Round"]
        )

        deal_types = result["Deal Type"].unique()
        assert len(deal_types) == 1
        assert deal_types[0] == "Seed Round"

    def test_excludes_non_vc_deal_types(self, temp_csv_file):
        """load_vc_deals should exclude non-VC deal types like Grant."""
        result = vc_loader.load_vc_deals(temp_csv_file)

        # DEAL007 has Deal Type = "Grant" which should be excluded
        assert "DEAL007" not in result["Deal ID"].values


# =============================================================================
# TEST: FILTERING BY DATE
# =============================================================================

class TestFilterByDate:
    """Tests for date filtering (2008+ by default)."""

    def test_filters_to_2008_and_later_by_default(self, temp_csv_mixed_dates):
        """load_vc_deals should filter to deals from 2008-01-01 onwards."""
        result = vc_loader.load_vc_deals(temp_csv_mixed_dates)

        # Should exclude DEAL001 (2005) and DEAL002 (2007)
        years = result["Year"].unique()
        assert all(year >= 2008 for year in years)

    def test_excludes_pre_2008_deals(self, temp_csv_mixed_dates):
        """load_vc_deals should exclude deals before 2008."""
        result = vc_loader.load_vc_deals(temp_csv_mixed_dates)

        # DEAL001 (2005) and DEAL002 (2007) should be excluded
        assert "DEAL001" not in result["Deal ID"].values
        assert "DEAL002" not in result["Deal ID"].values

    def test_includes_boundary_date_2008_01_01(self, temp_csv_mixed_dates):
        """load_vc_deals should include deals exactly on 2008-01-01."""
        result = vc_loader.load_vc_deals(temp_csv_mixed_dates)

        # DEAL003 (2008-01-01) should be included
        assert "DEAL003" in result["Deal ID"].values

    def test_custom_min_date_parameter(self, temp_csv_mixed_dates):
        """load_vc_deals should accept custom min_date parameter."""
        result = vc_loader.load_vc_deals(temp_csv_mixed_dates, min_date="2010-01-01")

        # Only DEAL004 (2010) and DEAL005 (2024) should remain
        years = result["Year"].unique()
        assert all(year >= 2010 for year in years)

    def test_default_min_date_constant(self):
        """MIN_DATE constant should be 2008-01-01."""
        assert vc_loader.MIN_DATE == "2008-01-01"


# =============================================================================
# TEST: FILTERING BY DEAL STATUS
# =============================================================================

class TestFilterByDealStatus:
    """Tests for deal status filtering (completed only)."""

    def test_filters_to_completed_deals_only(self, temp_csv_file):
        """load_vc_deals should only include completed deals."""
        result = vc_loader.load_vc_deals(temp_csv_file)

        statuses = result["Deal Status"].unique()
        assert len(statuses) == 1
        assert statuses[0] == "Completed"

    def test_excludes_pending_deals(self, temp_csv_file):
        """load_vc_deals should exclude pending deals."""
        result = vc_loader.load_vc_deals(temp_csv_file)

        # DEAL005 has Deal Status = "Pending" and should be excluded
        assert "DEAL005" not in result["Deal ID"].values


# =============================================================================
# TEST: DEAL SIZE PARSING
# =============================================================================

class TestDealSizeParsing:
    """Tests for deal size parsing and handling."""

    def test_removes_commas_from_deal_size(self, temp_csv_deal_sizes):
        """load_vc_deals should remove commas from deal size values."""
        result = vc_loader.load_vc_deals(temp_csv_deal_sizes)

        # Check that 1,500 becomes 1500.0
        small_deal = result[result["Deal ID"] == "DEAL001"]["Deal Size"].iloc[0]
        assert small_deal == 1500.0

    def test_handles_large_deal_sizes_with_multiple_commas(self, temp_csv_deal_sizes):
        """load_vc_deals should handle large deal sizes with multiple commas."""
        result = vc_loader.load_vc_deals(temp_csv_deal_sizes)

        # Check that 1,000,000 becomes 1000000.0
        large_deal = result[result["Deal ID"] == "DEAL003"]["Deal Size"].iloc[0]
        assert large_deal == 1000000.0

    def test_converts_deal_size_to_numeric(self, temp_csv_deal_sizes):
        """load_vc_deals should convert deal size to numeric type."""
        result = vc_loader.load_vc_deals(temp_csv_deal_sizes)
        assert pd.api.types.is_numeric_dtype(result["Deal Size"])

    def test_handles_empty_deal_size_as_nan(self, temp_csv_deal_sizes):
        """load_vc_deals should handle empty deal size as NaN."""
        result = vc_loader.load_vc_deals(temp_csv_deal_sizes)

        # DEAL004 has empty deal size
        no_deal = result[result["Deal ID"] == "DEAL004"]["Deal Size"].iloc[0]
        assert pd.isna(no_deal)

    def test_handles_zero_deal_size(self, temp_csv_deal_sizes):
        """load_vc_deals should handle zero deal size correctly."""
        result = vc_loader.load_vc_deals(temp_csv_deal_sizes)

        # DEAL005 has deal size of 0
        zero_deal = result[result["Deal ID"] == "DEAL005"]["Deal Size"].iloc[0]
        assert zero_deal == 0.0

    def test_handles_non_numeric_deal_size_as_nan(self, temp_csv_deal_sizes):
        """load_vc_deals should handle non-numeric deal size (e.g., N/A) as NaN."""
        result = vc_loader.load_vc_deals(temp_csv_deal_sizes)

        # DEAL006 has deal size of "N/A"
        text_deal = result[result["Deal ID"] == "DEAL006"]["Deal Size"].iloc[0]
        assert pd.isna(text_deal)


# =============================================================================
# TEST: STAGE CATEGORIZATION
# =============================================================================

class TestStageCategorizaton:
    """Tests for deal stage categorization."""

    def test_maps_seed_round_to_seed(self, temp_csv_file):
        """load_vc_deals should map Seed Round to Stage='Seed'."""
        result = vc_loader.load_vc_deals(temp_csv_file)

        seed_deals = result[result["Deal Type"] == "Seed Round"]
        assert all(seed_deals["Stage"] == "Seed")

    def test_maps_angel_to_seed(self, temp_csv_file):
        """load_vc_deals should map Angel (individual) to Stage='Seed'."""
        result = vc_loader.load_vc_deals(temp_csv_file)

        angel_deals = result[result["Deal Type"] == "Angel (individual)"]
        assert all(angel_deals["Stage"] == "Seed")

    def test_maps_early_stage_vc_to_early(self, temp_csv_file):
        """load_vc_deals should map Early Stage VC to Stage='Early'."""
        result = vc_loader.load_vc_deals(temp_csv_file)

        early_deals = result[result["Deal Type"] == "Early Stage VC"]
        assert all(early_deals["Stage"] == "Early")

    def test_maps_later_stage_vc_to_late(self, temp_csv_file):
        """load_vc_deals should map Later Stage VC to Stage='Late'."""
        result = vc_loader.load_vc_deals(temp_csv_file)

        late_deals = result[result["Deal Type"] == "Later Stage VC"]
        assert all(late_deals["Stage"] == "Late")


# =============================================================================
# TEST: get_deal_summary()
# =============================================================================

class TestGetDealSummary:
    """Tests for get_deal_summary() function."""

    def test_returns_dictionary(self, loaded_vc_df):
        """get_deal_summary should return a dictionary."""
        result = vc_loader.get_deal_summary(loaded_vc_df)
        assert isinstance(result, dict)

    def test_contains_total_deals(self, loaded_vc_df):
        """get_deal_summary should contain total_deals count."""
        result = vc_loader.get_deal_summary(loaded_vc_df)
        assert "total_deals" in result
        assert isinstance(result["total_deals"], int)
        assert result["total_deals"] == len(loaded_vc_df)

    def test_contains_date_range(self, loaded_vc_df):
        """get_deal_summary should contain date_range with start and end."""
        result = vc_loader.get_deal_summary(loaded_vc_df)

        assert "date_range" in result
        assert "start" in result["date_range"]
        assert "end" in result["date_range"]
        # Dates should be in YYYY-MM-DD format
        assert len(result["date_range"]["start"]) == 10
        assert len(result["date_range"]["end"]) == 10

    def test_contains_deals_with_size(self, loaded_vc_df):
        """get_deal_summary should contain deals_with_size count."""
        import numpy as np
        result = vc_loader.get_deal_summary(loaded_vc_df)

        assert "deals_with_size" in result
        assert isinstance(result["deals_with_size"], (int, float, np.integer))

    def test_contains_size_coverage_pct(self, loaded_vc_df):
        """get_deal_summary should contain size_coverage_pct."""
        result = vc_loader.get_deal_summary(loaded_vc_df)

        assert "size_coverage_pct" in result
        assert 0 <= result["size_coverage_pct"] <= 100

    def test_contains_deal_types(self, loaded_vc_df):
        """get_deal_summary should contain deal_types breakdown."""
        result = vc_loader.get_deal_summary(loaded_vc_df)

        assert "deal_types" in result
        assert isinstance(result["deal_types"], dict)

    def test_contains_stages(self, loaded_vc_df):
        """get_deal_summary should contain stages breakdown."""
        result = vc_loader.get_deal_summary(loaded_vc_df)

        assert "stages" in result
        assert isinstance(result["stages"], dict)

    def test_contains_top_sectors(self, loaded_vc_df):
        """get_deal_summary should contain top_sectors (top 10)."""
        result = vc_loader.get_deal_summary(loaded_vc_df)

        assert "top_sectors" in result
        assert isinstance(result["top_sectors"], dict)
        assert len(result["top_sectors"]) <= 10

    def test_contains_deals_by_year(self, loaded_vc_df):
        """get_deal_summary should contain deals_by_year breakdown."""
        result = vc_loader.get_deal_summary(loaded_vc_df)

        assert "deals_by_year" in result
        assert isinstance(result["deals_by_year"], dict)

    def test_size_coverage_calculation(self):
        """get_deal_summary should correctly calculate size coverage percentage."""
        # Create a DataFrame with known size coverage
        csv_content = """Header 1
Header 2
Header 3
Header 4
Header 5
Header 6
Deal ID,Companies,Company ID,Deal Date,Deal Size,Deal Type,Deal Status,Primary Industry Sector
DEAL001,Co1,COMP001,2024-01-15,"10,000",Seed Round,Completed,Energy
DEAL002,Co2,COMP002,2024-02-15,,Seed Round,Completed,Energy
DEAL003,Co3,COMP003,2024-03-15,"20,000",Seed Round,Completed,Energy
DEAL004,Co4,COMP004,2024-04-15,,Seed Round,Completed,Energy
"""
        path = write_temp_csv(csv_content)
        try:
            df = vc_loader.load_vc_deals(path)
            result = vc_loader.get_deal_summary(df)

            # 2 out of 4 deals have size data = 50%
            assert result["deals_with_size"] == 2
            assert result["size_coverage_pct"] == 50.0
        finally:
            os.unlink(path)


# =============================================================================
# TEST: VC_DEAL_TYPES CONSTANT
# =============================================================================

class TestVcDealTypesConstant:
    """Tests for VC_DEAL_TYPES constant."""

    def test_vc_deal_types_is_list(self):
        """VC_DEAL_TYPES should be a list."""
        assert isinstance(vc_loader.VC_DEAL_TYPES, list)

    def test_vc_deal_types_contains_expected_types(self):
        """VC_DEAL_TYPES should contain expected deal types."""
        expected = ["Seed Round", "Early Stage VC", "Later Stage VC", "Angel (individual)"]
        for dtype in expected:
            assert dtype in vc_loader.VC_DEAL_TYPES

    def test_vc_deal_types_has_four_types(self):
        """VC_DEAL_TYPES should have exactly 4 types."""
        assert len(vc_loader.VC_DEAL_TYPES) == 4


# =============================================================================
# TEST: EDGE CASES
# =============================================================================

class TestEdgeCases:
    """Tests for edge cases and error handling."""

    def test_handles_missing_columns_gracefully(self):
        """load_vc_deals should handle CSV with missing optional columns."""
        csv_content = """Header 1
Header 2
Header 3
Header 4
Header 5
Header 6
Deal ID,Companies,Deal Date,Deal Size,Deal Type,Deal Status
DEAL001,TestCo,2024-01-15,"10,000",Seed Round,Completed
"""
        path = write_temp_csv(csv_content)
        try:
            result = vc_loader.load_vc_deals(path)

            # Should still return a DataFrame with existing columns
            assert isinstance(result, pd.DataFrame)
            assert "Deal ID" in result.columns
        finally:
            os.unlink(path)

    def test_empty_result_after_filtering(self):
        """load_vc_deals should return empty DataFrame if all rows filtered."""
        csv_content = """Header 1
Header 2
Header 3
Header 4
Header 5
Header 6
Deal ID,Companies,Deal Date,Deal Size,Deal Type,Deal Status,Primary Industry Sector
DEAL001,OldCo,2005-01-15,"1,000",Seed Round,Completed,Energy
"""
        path = write_temp_csv(csv_content)
        try:
            result = vc_loader.load_vc_deals(path)

            # All deals are before 2008, so result should be empty
            assert len(result) == 0
            assert isinstance(result, pd.DataFrame)
        finally:
            os.unlink(path)

    def test_handles_invalid_date_format(self):
        """load_vc_deals should handle invalid date formats gracefully."""
        csv_content = """Header 1
Header 2
Header 3
Header 4
Header 5
Header 6
Deal ID,Companies,Deal Date,Deal Size,Deal Type,Deal Status,Primary Industry Sector
DEAL001,TestCo,invalid-date,"10,000",Seed Round,Completed,Energy
DEAL002,TestCo2,2024-01-15,"20,000",Seed Round,Completed,Energy
"""
        path = write_temp_csv(csv_content)
        try:
            result = vc_loader.load_vc_deals(path)

            # Invalid date should be coerced to NaT and filtered out
            assert len(result) == 1
            assert result["Deal ID"].iloc[0] == "DEAL002"
        finally:
            os.unlink(path)

    def test_handles_path_object(self):
        """load_vc_deals should accept pathlib.Path objects."""
        from pathlib import Path
        csv_content = """Header 1
Header 2
Header 3
Header 4
Header 5
Header 6
Deal ID,Companies,Deal Date,Deal Size,Deal Type,Deal Status,Primary Industry Sector
DEAL001,TestCo,2024-01-15,"10,000",Seed Round,Completed,Energy
"""
        str_path = write_temp_csv(csv_content)
        try:
            path_obj = Path(str_path)
            result = vc_loader.load_vc_deals(path_obj)

            assert isinstance(result, pd.DataFrame)
            assert len(result) == 1
        finally:
            os.unlink(str_path)
